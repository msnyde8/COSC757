
> 
> 
> 
> 
> 
> #### Input data set bakabce scale into Data Frame "balanceScaleData"
> balanceScaleData <- read.csv(file = "C:/Users/maryjoyce/Documents/Towson/Spring 2016/COSC 757/Assignments/Assignment2/UCI data/balance-scale.data", header = FALSE, sep = ",", stringsAsFactors = TRUE, col.names = c("class", "lWeight", "lDistance", "rWeight", "rDistance"))
> balanceScaleData[1:20,]
   class lWeight lDistance rWeight rDistance
1      B       1         1       1         1
2      R       1         1       1         2
3      R       1         1       1         3
4      R       1         1       1         4
5      R       1         1       1         5
6      R       1         1       2         1
7      R       1         1       2         2
8      R       1         1       2         3
9      R       1         1       2         4
10     R       1         1       2         5
11     R       1         1       3         1
12     R       1         1       3         2
13     R       1         1       3         3
14     R       1         1       3         4
15     R       1         1       3         5
16     R       1         1       4         1
17     R       1         1       4         2
18     R       1         1       4         3
19     R       1         1       4         4
20     R       1         1       4         5
> 
> ## Decision Tree Classification
> # install.packages("rpart")
> # library(rpart)
> set.seed(1234)
> ind <- sample(2, nrow(balanceScaleData), replace=TRUE,
+             prob=c(0.7,0.3))
> trainData <- balanceScaleData[ind==1,]
> testData <- balanceScaleData[ind==2,]
> # trainData$balanceData <- (trainData$rWeight * trainData$rDistance) - (trainData$lWeight * trainData$lDistance)
> # testData$balanceData <- (testData$rWeight * testData$rDistance) - (testData$lWeight * testData$lDistance)
> # balanceScale_rpart <- rpart(class ~ balanceData, data = trainData)
> balanceScale_rpart <- rpart(class ~ rWeight + rDistance + lWeight + lDistance, data = trainData, method = "class")
> printcp(balanceScale_rpart)

Classification tree:
rpart(formula = class ~ rWeight + rDistance + lWeight + lDistance, 
    data = trainData, method = "class")

Variables actually used in tree construction:
[1] lDistance lWeight   rDistance rWeight  

Root node error: 234/435 = 0.53793

n= 435 

        CP nsplit rel error  xerror     xstd
1 0.337607      0   1.00000 1.12393 0.043579
2 0.111111      1   0.66239 0.77350 0.043933
3 0.047009      2   0.55128 0.61111 0.041870
4 0.034188      3   0.50427 0.53846 0.040430
5 0.027778      5   0.43590 0.52137 0.040040
6 0.025641      7   0.38034 0.51709 0.039939
7 0.021368      8   0.35470 0.45726 0.038386
8 0.019231      9   0.33333 0.46154 0.038506
9 0.010000     11   0.29487 0.41880 0.037236
> plotcp(balanceScale_rpart)
> plot(balanceScale_rpart)
> text(balanceScale_rpart, use.n=TRUE)
> balanceScale_pred <- predict(balanceScale_rpart, newData = testData)
> balanceScale_pred
             B         L          R
1   0.21428571 0.2142857 0.57142857
2   0.25000000 0.1875000 0.56250000
3   0.25000000 0.1875000 0.56250000
4   0.25000000 0.1875000 0.56250000
6   0.21428571 0.2142857 0.57142857
7   0.05309735 0.0619469 0.88495575
8   0.05309735 0.0619469 0.88495575
9   0.05309735 0.0619469 0.88495575
10  0.05309735 0.0619469 0.88495575
11  0.21428571 0.2142857 0.57142857
12  0.05309735 0.0619469 0.88495575
13  0.05309735 0.0619469 0.88495575
15  0.05309735 0.0619469 0.88495575
17  0.05309735 0.0619469 0.88495575
18  0.05309735 0.0619469 0.88495575
19  0.05309735 0.0619469 0.88495575
20  0.05309735 0.0619469 0.88495575
21  0.21428571 0.2142857 0.57142857
22  0.05309735 0.0619469 0.88495575
23  0.05309735 0.0619469 0.88495575
24  0.05309735 0.0619469 0.88495575
25  0.05309735 0.0619469 0.88495575
27  0.07142857 0.7857143 0.14285714
30  0.07142857 0.7857143 0.14285714
31  0.21428571 0.2142857 0.57142857
32  0.05309735 0.0619469 0.88495575
33  0.05309735 0.0619469 0.88495575
34  0.05309735 0.0619469 0.88495575
35  0.05309735 0.0619469 0.88495575
37  0.05309735 0.0619469 0.88495575
38  0.05309735 0.0619469 0.88495575
41  0.21428571 0.2142857 0.57142857
42  0.05309735 0.0619469 0.88495575
43  0.05309735 0.0619469 0.88495575
44  0.05309735 0.0619469 0.88495575
45  0.05309735 0.0619469 0.88495575
46  0.21428571 0.2142857 0.57142857
47  0.05309735 0.0619469 0.88495575
48  0.05309735 0.0619469 0.88495575
49  0.05309735 0.0619469 0.88495575
51  0.14285714 0.6428571 0.21428571
52  0.14285714 0.6428571 0.21428571
54  0.14285714 0.6428571 0.21428571
55  0.14285714 0.6428571 0.21428571
56  0.05000000 0.0750000 0.87500000
57  0.05000000 0.0750000 0.87500000
59  0.05000000 0.0750000 0.87500000
62  0.05000000 0.0750000 0.87500000
63  0.05000000 0.0750000 0.87500000
64  0.05000000 0.0750000 0.87500000
65  0.05000000 0.0750000 0.87500000
67  0.05000000 0.0750000 0.87500000
68  0.05000000 0.0750000 0.87500000
69  0.05000000 0.0750000 0.87500000
70  0.05000000 0.0750000 0.87500000
71  0.05000000 0.0750000 0.87500000
73  0.05000000 0.0750000 0.87500000
75  0.05000000 0.0750000 0.87500000
76  0.14285714 0.6428571 0.21428571
77  0.14285714 0.6428571 0.21428571
78  0.14285714 0.6428571 0.21428571
79  0.14285714 0.6428571 0.21428571
80  0.14285714 0.6428571 0.21428571
82  0.05000000 0.0750000 0.87500000
83  0.05000000 0.0750000 0.87500000
84  0.05000000 0.0750000 0.87500000
85  0.05000000 0.0750000 0.87500000
87  0.05000000 0.0750000 0.87500000
88  0.05000000 0.0750000 0.87500000
89  0.05000000 0.0750000 0.87500000
91  0.05000000 0.0750000 0.87500000
93  0.05000000 0.0750000 0.87500000
94  0.05000000 0.0750000 0.87500000
95  0.05000000 0.0750000 0.87500000
96  0.05000000 0.0750000 0.87500000
97  0.05000000 0.0750000 0.87500000
98  0.05000000 0.0750000 0.87500000
99  0.05000000 0.0750000 0.87500000
101 0.14285714 0.6428571 0.21428571
102 0.14285714 0.6428571 0.21428571
103 0.14285714 0.6428571 0.21428571
104 0.14285714 0.6428571 0.21428571
105 0.14285714 0.6428571 0.21428571
106 0.05000000 0.0750000 0.87500000
107 0.05000000 0.0750000 0.87500000
108 0.05000000 0.0750000 0.87500000
109 0.05000000 0.0750000 0.87500000
110 0.05000000 0.0750000 0.87500000
112 0.05000000 0.0750000 0.87500000
114 0.05000000 0.0750000 0.87500000
115 0.05000000 0.0750000 0.87500000
118 0.05000000 0.0750000 0.87500000
119 0.05000000 0.0750000 0.87500000
125 0.05000000 0.0750000 0.87500000
126 0.21428571 0.2142857 0.57142857
127 0.25000000 0.1875000 0.56250000
128 0.25000000 0.1875000 0.56250000
129 0.25000000 0.1875000 0.56250000
130 0.25000000 0.1875000 0.56250000
132 0.05309735 0.0619469 0.88495575
133 0.05309735 0.0619469 0.88495575
134 0.05309735 0.0619469 0.88495575
136 0.21428571 0.2142857 0.57142857
138 0.05309735 0.0619469 0.88495575
139 0.05309735 0.0619469 0.88495575
141 0.21428571 0.2142857 0.57142857
143 0.05309735 0.0619469 0.88495575
144 0.05309735 0.0619469 0.88495575
145 0.05309735 0.0619469 0.88495575
146 0.21428571 0.2142857 0.57142857
148 0.05309735 0.0619469 0.88495575
150 0.05309735 0.0619469 0.88495575
151 0.21428571 0.2142857 0.57142857
152 0.07142857 0.7857143 0.14285714
153 0.07142857 0.7857143 0.14285714
155 0.07142857 0.7857143 0.14285714
157 0.05309735 0.0619469 0.88495575
159 0.05309735 0.0619469 0.88495575
160 0.05309735 0.0619469 0.88495575
161 0.21428571 0.2142857 0.57142857
162 0.05309735 0.0619469 0.88495575
163 0.05309735 0.0619469 0.88495575
164 0.05309735 0.0619469 0.88495575
165 0.05309735 0.0619469 0.88495575
166 0.21428571 0.2142857 0.57142857
167 0.05309735 0.0619469 0.88495575
168 0.05309735 0.0619469 0.88495575
170 0.05309735 0.0619469 0.88495575
172 0.05309735 0.0619469 0.88495575
174 0.05309735 0.0619469 0.88495575
175 0.05309735 0.0619469 0.88495575
177 0.01265823 0.9746835 0.01265823
178 0.06000000 0.9200000 0.02000000
179 0.06000000 0.9200000 0.02000000
180 0.06000000 0.9200000 0.02000000
181 0.01265823 0.9746835 0.01265823
182 0.01265823 0.9746835 0.01265823
183 0.06000000 0.9200000 0.02000000
184 0.06000000 0.9200000 0.02000000
186 0.01265823 0.9746835 0.01265823
188 0.05882353 0.1470588 0.79411765
189 0.05882353 0.1470588 0.79411765
191 0.01265823 0.9746835 0.01265823
193 0.05882353 0.1470588 0.79411765
200 0.05882353 0.1470588 0.79411765
201 0.01265823 0.9746835 0.01265823
202 0.01265823 0.9746835 0.01265823
203 0.06000000 0.9200000 0.02000000
205 0.06000000 0.9200000 0.02000000
207 0.01265823 0.9746835 0.01265823
208 0.06000000 0.9200000 0.02000000
209 0.06000000 0.9200000 0.02000000
211 0.01265823 0.9746835 0.01265823
212 0.01265823 0.9746835 0.01265823
213 0.05882353 0.1470588 0.79411765
215 0.05882353 0.1470588 0.79411765
217 0.01265823 0.9746835 0.01265823
219 0.05882353 0.1470588 0.79411765
221 0.01265823 0.9746835 0.01265823
222 0.01265823 0.9746835 0.01265823
223 0.05882353 0.1470588 0.79411765
224 0.05882353 0.1470588 0.79411765
225 0.05882353 0.1470588 0.79411765
226 0.01265823 0.9746835 0.01265823
228 0.06000000 0.9200000 0.02000000
229 0.06000000 0.9200000 0.02000000
230 0.06000000 0.9200000 0.02000000
232 0.01265823 0.9746835 0.01265823
233 0.06000000 0.9200000 0.02000000
235 0.06000000 0.9200000 0.02000000
236 0.01265823 0.9746835 0.01265823
238 0.05882353 0.1470588 0.79411765
239 0.05882353 0.1470588 0.79411765
241 0.01265823 0.9746835 0.01265823
242 0.01265823 0.9746835 0.01265823
243 0.05882353 0.1470588 0.79411765
244 0.05882353 0.1470588 0.79411765
246 0.01265823 0.9746835 0.01265823
248 0.05882353 0.1470588 0.79411765
251 0.04761905 0.8571429 0.09523810
252 0.25000000 0.1875000 0.56250000
253 0.25000000 0.1875000 0.56250000
254 0.25000000 0.1875000 0.56250000
255 0.25000000 0.1875000 0.56250000
256 0.04761905 0.8571429 0.09523810
257 0.05309735 0.0619469 0.88495575
258 0.05309735 0.0619469 0.88495575
259 0.05309735 0.0619469 0.88495575
260 0.05309735 0.0619469 0.88495575
262 0.05309735 0.0619469 0.88495575
263 0.05309735 0.0619469 0.88495575
264 0.05309735 0.0619469 0.88495575
265 0.05309735 0.0619469 0.88495575
266 0.04761905 0.8571429 0.09523810
268 0.05309735 0.0619469 0.88495575
269 0.05309735 0.0619469 0.88495575
271 0.04761905 0.8571429 0.09523810
273 0.05309735 0.0619469 0.88495575
275 0.05309735 0.0619469 0.88495575
276 0.04761905 0.8571429 0.09523810
278 0.07142857 0.7857143 0.14285714
279 0.07142857 0.7857143 0.14285714
280 0.07142857 0.7857143 0.14285714
281 0.04761905 0.8571429 0.09523810
282 0.05309735 0.0619469 0.88495575
286 0.04761905 0.8571429 0.09523810
287 0.05309735 0.0619469 0.88495575
288 0.05309735 0.0619469 0.88495575
289 0.05309735 0.0619469 0.88495575
291 0.04761905 0.8571429 0.09523810
292 0.05309735 0.0619469 0.88495575
294 0.05309735 0.0619469 0.88495575
295 0.05309735 0.0619469 0.88495575
297 0.05309735 0.0619469 0.88495575
298 0.05309735 0.0619469 0.88495575
299 0.05309735 0.0619469 0.88495575
300 0.05309735 0.0619469 0.88495575
301 0.01265823 0.9746835 0.01265823
303 0.06000000 0.9200000 0.02000000
304 0.06000000 0.9200000 0.02000000
306 0.01265823 0.9746835 0.01265823
307 0.01265823 0.9746835 0.01265823
309 0.06000000 0.9200000 0.02000000
312 0.01265823 0.9746835 0.01265823
313 0.05882353 0.1470588 0.79411765
314 0.05882353 0.1470588 0.79411765
315 0.05882353 0.1470588 0.79411765
316 0.01265823 0.9746835 0.01265823
317 0.01265823 0.9746835 0.01265823
318 0.05882353 0.1470588 0.79411765
319 0.05882353 0.1470588 0.79411765
321 0.01265823 0.9746835 0.01265823
323 0.05882353 0.1470588 0.79411765
324 0.05882353 0.1470588 0.79411765
325 0.05882353 0.1470588 0.79411765
326 0.01265823 0.9746835 0.01265823
327 0.01265823 0.9746835 0.01265823
328 0.06000000 0.9200000 0.02000000
329 0.06000000 0.9200000 0.02000000
334 0.06000000 0.9200000 0.02000000
335 0.06000000 0.9200000 0.02000000
336 0.01265823 0.9746835 0.01265823
337 0.01265823 0.9746835 0.01265823
338 0.05882353 0.1470588 0.79411765
340 0.05882353 0.1470588 0.79411765
342 0.01265823 0.9746835 0.01265823
343 0.05882353 0.1470588 0.79411765
345 0.05882353 0.1470588 0.79411765
346 0.01265823 0.9746835 0.01265823
347 0.01265823 0.9746835 0.01265823
348 0.05882353 0.1470588 0.79411765
350 0.05882353 0.1470588 0.79411765
351 0.01265823 0.9746835 0.01265823
353 0.06000000 0.9200000 0.02000000
357 0.01265823 0.9746835 0.01265823
359 0.06000000 0.9200000 0.02000000
361 0.01265823 0.9746835 0.01265823
362 0.01265823 0.9746835 0.01265823
363 0.05882353 0.1470588 0.79411765
364 0.05882353 0.1470588 0.79411765
367 0.01265823 0.9746835 0.01265823
368 0.05882353 0.1470588 0.79411765
372 0.01265823 0.9746835 0.01265823
374 0.05882353 0.1470588 0.79411765
375 0.05882353 0.1470588 0.79411765
376 0.04761905 0.8571429 0.09523810
378 0.25000000 0.1875000 0.56250000
379 0.25000000 0.1875000 0.56250000
380 0.25000000 0.1875000 0.56250000
381 0.04761905 0.8571429 0.09523810
382 0.05309735 0.0619469 0.88495575
383 0.05309735 0.0619469 0.88495575
384 0.05309735 0.0619469 0.88495575
385 0.05309735 0.0619469 0.88495575
386 0.04761905 0.8571429 0.09523810
387 0.05309735 0.0619469 0.88495575
388 0.05309735 0.0619469 0.88495575
391 0.04761905 0.8571429 0.09523810
394 0.05309735 0.0619469 0.88495575
395 0.05309735 0.0619469 0.88495575
397 0.05309735 0.0619469 0.88495575
398 0.05309735 0.0619469 0.88495575
399 0.05309735 0.0619469 0.88495575
400 0.05309735 0.0619469 0.88495575
401 0.04761905 0.8571429 0.09523810
402 0.07142857 0.7857143 0.14285714
405 0.07142857 0.7857143 0.14285714
406 0.04761905 0.8571429 0.09523810
408 0.05309735 0.0619469 0.88495575
409 0.05309735 0.0619469 0.88495575
410 0.05309735 0.0619469 0.88495575
414 0.05309735 0.0619469 0.88495575
416 0.04761905 0.8571429 0.09523810
417 0.05309735 0.0619469 0.88495575
419 0.05309735 0.0619469 0.88495575
420 0.05309735 0.0619469 0.88495575
421 0.04761905 0.8571429 0.09523810
423 0.05309735 0.0619469 0.88495575
424 0.05309735 0.0619469 0.88495575
426 0.01265823 0.9746835 0.01265823
427 0.01265823 0.9746835 0.01265823
428 0.06000000 0.9200000 0.02000000
429 0.06000000 0.9200000 0.02000000
430 0.06000000 0.9200000 0.02000000
431 0.01265823 0.9746835 0.01265823
433 0.06000000 0.9200000 0.02000000
435 0.06000000 0.9200000 0.02000000
436 0.01265823 0.9746835 0.01265823
437 0.01265823 0.9746835 0.01265823
440 0.15384615 0.1538462 0.69230769
444 0.15384615 0.1538462 0.69230769
446 0.01265823 0.9746835 0.01265823
448 0.15384615 0.1538462 0.69230769
449 0.15384615 0.1538462 0.69230769
450 0.15384615 0.1538462 0.69230769
451 0.01265823 0.9746835 0.01265823
456 0.01265823 0.9746835 0.01265823
457 0.01265823 0.9746835 0.01265823
458 0.06000000 0.9200000 0.02000000
459 0.06000000 0.9200000 0.02000000
460 0.06000000 0.9200000 0.02000000
461 0.01265823 0.9746835 0.01265823
463 0.22222222 0.6296296 0.14814815
464 0.22222222 0.6296296 0.14814815
465 0.22222222 0.6296296 0.14814815
466 0.01265823 0.9746835 0.01265823
467 0.01265823 0.9746835 0.01265823
468 0.22222222 0.6296296 0.14814815
469 0.22222222 0.6296296 0.14814815
470 0.22222222 0.6296296 0.14814815
471 0.01265823 0.9746835 0.01265823
472 0.01265823 0.9746835 0.01265823
473 0.22222222 0.6296296 0.14814815
475 0.22222222 0.6296296 0.14814815
477 0.01265823 0.9746835 0.01265823
478 0.06000000 0.9200000 0.02000000
480 0.06000000 0.9200000 0.02000000
481 0.01265823 0.9746835 0.01265823
482 0.01265823 0.9746835 0.01265823
483 0.06000000 0.9200000 0.02000000
484 0.06000000 0.9200000 0.02000000
485 0.06000000 0.9200000 0.02000000
486 0.01265823 0.9746835 0.01265823
490 0.22222222 0.6296296 0.14814815
491 0.01265823 0.9746835 0.01265823
494 0.22222222 0.6296296 0.14814815
495 0.22222222 0.6296296 0.14814815
496 0.01265823 0.9746835 0.01265823
497 0.01265823 0.9746835 0.01265823
498 0.22222222 0.6296296 0.14814815
499 0.22222222 0.6296296 0.14814815
500 0.22222222 0.6296296 0.14814815
501 0.04761905 0.8571429 0.09523810
504 0.25000000 0.1875000 0.56250000
505 0.25000000 0.1875000 0.56250000
509 0.05309735 0.0619469 0.88495575
511 0.04761905 0.8571429 0.09523810
514 0.05309735 0.0619469 0.88495575
515 0.05309735 0.0619469 0.88495575
517 0.05309735 0.0619469 0.88495575
518 0.05309735 0.0619469 0.88495575
519 0.05309735 0.0619469 0.88495575
520 0.05309735 0.0619469 0.88495575
522 0.05309735 0.0619469 0.88495575
523 0.05309735 0.0619469 0.88495575
525 0.05309735 0.0619469 0.88495575
527 0.07142857 0.7857143 0.14285714
528 0.07142857 0.7857143 0.14285714
529 0.07142857 0.7857143 0.14285714
530 0.07142857 0.7857143 0.14285714
531 0.04761905 0.8571429 0.09523810
532 0.05309735 0.0619469 0.88495575
533 0.05309735 0.0619469 0.88495575
535 0.05309735 0.0619469 0.88495575
537 0.05309735 0.0619469 0.88495575
538 0.05309735 0.0619469 0.88495575
540 0.05309735 0.0619469 0.88495575
541 0.04761905 0.8571429 0.09523810
542 0.05309735 0.0619469 0.88495575
544 0.05309735 0.0619469 0.88495575
546 0.04761905 0.8571429 0.09523810
551 0.01265823 0.9746835 0.01265823
552 0.01265823 0.9746835 0.01265823
554 0.06000000 0.9200000 0.02000000
557 0.01265823 0.9746835 0.01265823
558 0.06000000 0.9200000 0.02000000
559 0.06000000 0.9200000 0.02000000
561 0.01265823 0.9746835 0.01265823
563 0.15384615 0.1538462 0.69230769
565 0.15384615 0.1538462 0.69230769
568 0.15384615 0.1538462 0.69230769
569 0.15384615 0.1538462 0.69230769
570 0.15384615 0.1538462 0.69230769
571 0.01265823 0.9746835 0.01265823
573 0.15384615 0.1538462 0.69230769
574 0.15384615 0.1538462 0.69230769
575 0.15384615 0.1538462 0.69230769
576 0.01265823 0.9746835 0.01265823
577 0.01265823 0.9746835 0.01265823
578 0.06000000 0.9200000 0.02000000
579 0.06000000 0.9200000 0.02000000
582 0.01265823 0.9746835 0.01265823
583 0.06000000 0.9200000 0.02000000
584 0.06000000 0.9200000 0.02000000
585 0.06000000 0.9200000 0.02000000
586 0.01265823 0.9746835 0.01265823
587 0.01265823 0.9746835 0.01265823
590 0.22222222 0.6296296 0.14814815
593 0.22222222 0.6296296 0.14814815
594 0.22222222 0.6296296 0.14814815
595 0.22222222 0.6296296 0.14814815
596 0.01265823 0.9746835 0.01265823
597 0.01265823 0.9746835 0.01265823
598 0.22222222 0.6296296 0.14814815
599 0.22222222 0.6296296 0.14814815
600 0.22222222 0.6296296 0.14814815
601 0.01265823 0.9746835 0.01265823
602 0.01265823 0.9746835 0.01265823
603 0.06000000 0.9200000 0.02000000
604 0.06000000 0.9200000 0.02000000
605 0.06000000 0.9200000 0.02000000
606 0.01265823 0.9746835 0.01265823
608 0.06000000 0.9200000 0.02000000
609 0.06000000 0.9200000 0.02000000
610 0.06000000 0.9200000 0.02000000
611 0.01265823 0.9746835 0.01265823
613 0.22222222 0.6296296 0.14814815
614 0.22222222 0.6296296 0.14814815
616 0.01265823 0.9746835 0.01265823
617 0.01265823 0.9746835 0.01265823
618 0.22222222 0.6296296 0.14814815
620 0.22222222 0.6296296 0.14814815
622 0.01265823 0.9746835 0.01265823
623 0.22222222 0.6296296 0.14814815
625 0.22222222 0.6296296 0.14814815
> 
> ## Naive Bayes Classification
> # install.packages("e1071")
> # library(class)
> # library(e1071)
> # classifier <- naiveBayes(class ~ balanceData, data = trainData)
> classifier <- naiveBayes(class ~ rWeight + rDistance + lWeight + lDistance, data = trainData, method = "class")
> pred <- predict(classifier, testData[,-5])
> table(pred,testData$class)
    
pred  B  L  R
   B  0  0  0
   L  5 74 14
   R 11 13 73
> 
> ## Random Forest?
> # install.packages("randomForest")
> # library(randomForest)
> # fit <- randomForest(class ~ balanceData, data = trainData)
> fit <- randomForest(class ~ rWeight + rDistance + lWeight + lDistance, data = trainData, method = "class")
> print(fit)

Call:
 randomForest(formula = class ~ rWeight + rDistance + lWeight +      lDistance, data = trainData, method = "class") 
               Type of random forest: classification
                     Number of trees: 500
No. of variables tried at each split: 2

        OOB estimate of  error rate: 14.02%
Confusion matrix:
  B   L   R class.error
B 0  16  17  1.00000000
L 7 189   5  0.05970149
R 9   7 185  0.07960199
> importance(fit)
          MeanDecreaseGini
rWeight           54.83161
rDistance         54.47461
lWeight           55.76208
lDistance         58.52633